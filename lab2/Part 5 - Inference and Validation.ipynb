{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс и валидация\n",
    "\n",
    "Теперь, когда у вас есть обученная сеть, вы можете использовать её для прогнозирования. Это обычно называется **инференсом** (inference). Однако нейронные сети имеют тенденцию показывать *слишком хорошие* результаты на обучающих данных и не могут обобщать свою работу на данные, которые не были доступны при обучении. Это называется **переобучением**, и оно ухудшает качество инференса. Чтобы проверить наличие переобучения в процессе обучения, мы измеряем метрики на данных, не входящих в обучающий набор, которые называют **валидационным** набором. Мы избегаем переобучения с помощью регуляризации, такой как дроп-аут, в то время как следим за метриками на валидационной выборке в процессе обучения. В этом блокноте покажем, как это сделать в PyTorch. \n",
    "\n",
    "Как обычно, давайте начнём с загрузки набора данных через torchvision. Вы узнаете больше о torchvision и загрузке данных в следующей части. На этот раз мы воспользуемся тестовым набором, который вы можете получить, установив `train=False`:\n",
    "\n",
    "```python\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "```\n",
    "\n",
    "Тестовый набор содержит изображения, точно так же, как и тренировочный набор. Обычно вы увидите, что 10-20% оригинального набора данных отложены для тестирования и валидации, а оставшаяся часть используется для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Определим трансформацию для нормализации данных\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Загрузим тренировочные данные\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Загрузим тестовые данные\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # убедимся, что входной тензор развернут в вектор-строку (flattened)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель валидации состоит в том, чтобы измерить метрики модели на данных, которые не входят в тренировочный набор. Выбор метрик зависит во многом от разработчика. Обычно это просто точность (accuracy), процент классов, которые сеть предсказывает правильно. Другие варианты включают [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)) и top-5 error rate. Здесь мы сосредоточимся на точности. Сначала сделаем прямой проход с одним батчем из тестового набора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "# Получим вероятности классов\n",
    "ps = torch.exp(model(images))\n",
    "# Убедимся, что форма правильная, мы должны получить 10 вероятностей классов для 64 примеров\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С вероятностями мы можем получить наиболее вероятный класс, используя метод `ps.topk`. Это возвращает $k$ наивысших значений. Поскольку мы просто хотим наиболее вероятный класс, мы можем использовать `ps.topk(1)`. Это возвращает кортеж из наивысших значений и соответствующих индексов. Если наивысшее значение является пятым элементом, мы получим 4 как индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "# Посмотрим на наиболее вероятные классы для первых 10 примеров\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем проверить, совпадают ли предсказанные классы с метками. Это легко сделать, сравнив `top_class` и `labels`, но мы должны быть осторожны с формами. Здесь `top_class` — это 2D тензор с формой `(64, 1)`, а `labels` — это 1D с формой `(64)`. Чтобы получить нужное равенство, `top_class` и `labels` должны иметь одинаковую форму.\n",
    "\n",
    "Если мы сделаем\n",
    "\n",
    "```python\n",
    "equals = top_class == labels\n",
    "```\n",
    "\n",
    "`equals` будет иметь форму `(64, 64)`. Происходит сравнение одного элемента в каждой строке `top_class` с каждым элементом в `labels`, что возвращает 64 значения True/False для каждой строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = top_class == labels.view(*top_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно рассчитать процент правильных предсказаний. `equals` имеет двоичные значения, либо 0, либо 1. Это означает, что если мы просто суммируем все значения и делим на количество значений, мы получим процент правильных предсказаний. Это та же операция, что и вычисление среднего, поэтому мы можем получить точность с помощью вызова `torch.mean`. Если бы все было так просто. Если вы попробуете `torch.mean(equals)`, вы получите ошибку\n",
    "\n",
    "```\n",
    "RuntimeError: mean is not implemented for type torch.ByteTensor\n",
    "```\n",
    "\n",
    "Это происходит потому, что `equals` имеет тип `torch.ByteTensor`, но для этого типа `torch.mean` не реализован. Поэтому нам нужно преобразовать `equals` в float тензор с плавающей запятой. Обратите внимание, что когда мы вызываем `torch.mean`, это возвращает скалярный тензор. Чтобы получить фактическое значение как float, нам нужно будет использовать `accuracy.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Точность: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сеть не обучена, поэтому она делает случайные предположения, и мы должны увидеть точность около 10%. Теперь давайте обучим нашу сеть и включим шаг валидации, чтобы измерить, насколько хорошо сеть работает на тестовом наборе. Поскольку мы не обновляем параметры в цикле валидации, мы можем ускорить процесс, отключив градиенты с помощью `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "# отключение градиентов\n",
    "with torch.no_grad():\n",
    "    # валидация\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "```\n",
    "\n",
    ">**Упражнение:** Реализуйте обучение сети совместно с циклом валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        ## TODO: Реализуйте цикл валидации и вывод точности на валидационной выборке\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переобучение (overfitting)\n",
    "\n",
    "Если мы посмотрим на функцию потерь при обучении и валидации по мере обучения сети, мы можем увидеть явление, известное как переобучение (overfitting).\n",
    "\n",
    "<img src='assets/overfitting.png' width=450px>\n",
    "\n",
    "Сеть учит тренировочный набор всё лучше и лучше, что приводит к снижению потерь при обучении. Однако она начинает испытывать проблемы с обобщением данных, выходящих за пределы тренировочного набора, что приводит к росту потерь на валидации. Конечная цель любой модели глубокого обучения — делать предсказания на новых данных, поэтому мы должны стремиться получить как можно более низкую потерю на валидации. Один из вариантов — использовать версию модели с наименьшей потерей на валидации, здесь это версия примерно через 8-10 эпох обучения. Эта стратегия называется *ранней остановкой* (early-stopping). На практике вы будете сохранять модель регулярно, пока обучаете её, а затем позже выбирать модель с наименьшей потерей на валидации.\n",
    "\n",
    "Наиболее распространённым методом снижения переобучения (помимо ранней остановки) является *дроп-аут* (dropout), когда мы случайным образом исключаем узлы. Это заставляет сеть делиться информацией между весами, увеличивая её способность обобщать работу на новые данные. Добавить дроп-аут в PyTorch очень просто, используя модуль [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout).\n",
    "\n",
    "```python\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Модуль дропаута с вероятностью исключения 0.2\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # убедимся, что входной тензор развернут (flattened)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # Теперь с дроп-аутом\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        # вывод, поэтому без дропаута\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "```\n",
    "\n",
    "Во время обучения мы хотим использовать дроп-аут, чтобы предотвратить переобучение, но во время инференса мы хотим использовать всю сеть. Поэтому нам нужно отключить дроп-аут во время валидации, тестирования и когда мы используем сеть для предсказаний. Для этого используйте `model.eval()`. Это устанавливает модель в режим валидации (evaluation mode), где вероятность дропаута равна 0. Вы можете снова включить дроп-аут, установив модель в режим обучения с помощью `model.train()`. В общем, структура цикла валидации будет выглядеть следующим образом: вы отключаете градиенты, устанавливаете модель в режим валидации, вычисляете функцию потерь и метрики валидации, а затем возвращаете модель в режим обучения.\n",
    "\n",
    "```python\n",
    "# отключение градиентов\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # установить модель в режим оценки\n",
    "    model.eval()\n",
    "    \n",
    "    # валидационный проход здесь\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "\n",
    "# вернуть модель в режим обучения\n",
    "model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Упражнение:** Добавьте дроп-аут в вашу модель и обучите её снова на Fashion-MNIST. Посмотрите, сможете ли вы получить более низкую потерю на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Определите модель с добавленным дроп-аутом\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Обучите модель с дроп-аутом, добавьте мониторинг обучения с расчетом функции потерь и точности на валидационной выборке\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инференс (inference)\n",
    "\n",
    "Теперь, когда модель обучена, мы можем использовать её для инференса. Мы уже делали это раньше, но теперь нам нужно помнить о установке модели в режим валидации с `model.eval()`. Также можно отключить autograd с помощью менеджера контекста `torch.no_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем вспомогательный модуль (должен находиться в репозитории)\n",
    "import helper\n",
    "\n",
    "# Примените свою сеть.\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "img = images[0]\n",
    "# Преобразуем 2D изображение в 1D вектор\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Рассчитаем вероятности классов (softmax) для img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Построим изображение и вероятности\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующей части будет продемонстрировано, как сохранить ваши обученные модели. Обычно вы не хотите обучать модель каждый раз, когда она вам нужна. Вместо этого вы будете обучать один раз, сохранять её, а затем загружать модель, когда захотите обучить подольше или использовать её для инференса."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
