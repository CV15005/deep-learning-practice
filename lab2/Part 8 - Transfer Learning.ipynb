{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "В этом блокноте вы научитесь использовать предобученные сети для решения задач в области компьютерного зрения. В частности, вы будете использовать сети, обученные на [ImageNet](http://www.image-net.org/) [доступно из torchvision](https://pytorch.org/vision/main/models.html). \n",
    "\n",
    "ImageNet — это обширный набор данных с более чем 1 миллионом размеченных изображений и 1000 категорий. Он используется для обучения глубоких свёрточных нейронных сетей. Свёрточные сети мы подробнее рассмотрим на следующей лабораторной.\n",
    "\n",
    "После обучения эти модели работают удивительно хорошо для извлечения признаков из изображений, на которых они не были обучены. Использование заранее обученной сети на изображениях, которых нет в обучающем наборе, называется transfer learning (перенос обучения). Здесь мы будем использовать transfer learning, чтобы обучить сеть, которая может классифицировать фотографии кошек и собак с почти идеальной точностью.\n",
    "\n",
    "С помощью `torchvision.models` вы можете загрузить эти предобученные сети и использовать их в своих приложениях. Добавим `models` в наши импорты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство предобученных моделей требуют, чтобы входные данные были изображениями размером 224x224. Также нам нужно использовать ту же нормализацию, что использовалась при обучении моделей. Каждый цветовой канал нормализовался отдельно, средние значения составляют `[0.485, 0.456, 0.406]`, а стандартные отклонения — `[0.229, 0.224, 0.225]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# TODO: Определите преобразования для обучающего и тестового наборов данных\n",
    "train_transforms = \n",
    "\n",
    "test_transforms = \n",
    "\n",
    "# Примените преобразования, создайте объекты датасетов и загрузчиков данных для обучающего и тестового наборов\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим модель, такую как [DenseNet](https://pytorch.org/vision/main/models/generated/torchvision.models.densenet121.html). Давайте выведем архитектуру модели, чтобы увидеть ее составные блоки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта модель состоит из двух основных частей: \"извлекателя\" признаков и классификатора. \"Извлекатель\" признаков — это стек свёрточных слоёв, который в целом формирует набор признаков, который можно передать классификатору. Часть классификатора — это один полносвязный слой `(classifier): Linear(in_features=1024, out_features=1000)`. Этот слой был обучен на наборе данных ImageNet, поэтому он не подойдёт для нашей конкретной задачи. Это означает, что нам нужно заменить классификатор, но признаки будут работать идеально сами по себе. В общем, заранее обученные сети можно понимать как удивительно хорошие детекторы признаков, которые могут использоваться в качестве входных данных для простых классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замораживаем параметры, чтобы мы не могли выполнить обратное распространение ошибки через них\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем нам необходимо обучить классификатор. Однако теперь мы используем **очень глубокую** нейронную сеть. Если вы попытаетесь обучить её на центральном процессоре, как обычно, это займет очень много времени. Вместо этого мы будем использовать графический процессор (GPU) для выполнения вычислений. Вычисления линейной алгебры выполняются параллельно на GPU, что приводит к увеличению скорости обучения в 100 раз. Также возможно обучение на нескольких GPU, что ещё больше сокращает время обучения.\n",
    "\n",
    "PyTorch, наряду с практически всеми другими фреймворками глубокого обучения, использует [CUDA](https://developer.nvidia.com/cuda-zone) для эффективного выполнения прямых и обратных проходов на GPU. В PyTorch вы перемещаете параметры вашей модели и другие тензоры в память GPU, используя `model.to('cuda')`. Вы можете перемещать их обратно с GPU с помощью `model.to('cpu')`, что вам часто нужно делать, когда вам нужно работать с выходом сети вне PyTorch. В качестве демонстрации увеличенной скорости сравним, сколько времени требуется для выполнения прямого и обратного прохода с помощью и без графического процессора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in ['cpu', 'cuda']:\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Обучаем только параметры классификатора, параметры извлечения признаков заморожены\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "        # Перемещаем тензоры входных данных и меток на GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ii==3:\n",
    "            break\n",
    "        \n",
    "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно писать код, не зависимый от устройства, который будет автоматически использовать CUDA, если оно включено, следующим образом:\n",
    "```python\n",
    "# в начале скрипта\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "...\n",
    "\n",
    "# а затем каждый раз, когда вы получаете новый Тензор или Модуль, выполните следующий вызов\n",
    "# это не будет приводить к копированию, если они уже находятся на желаемом устройстве\n",
    "input = data.to(device)\n",
    "model = MyModule(...).to(device)\n",
    "```\n",
    "\n",
    "Закончите обучение модели самостоятельно. Процесс такой же, как и раньше, за исключением того, что теперь ваша модель намного мощнее. Вы должны легко получить точность выше 95%.\n",
    "\n",
    ">**Упражнение:** Обучите предобученную модель на классификацию изображений кошек и собак. Продолжайте работать с моделью DenseNet или попробуйте ResNet — это тоже хорошая модель для первого ознакомления. Убедитесь, что вы обучаете только классификатор, а параметры извлечения признаков заморожены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
