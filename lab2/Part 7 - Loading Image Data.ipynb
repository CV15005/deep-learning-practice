{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка изображений\n",
    "\n",
    "До сих пор мы работали с довольно искусственными наборами данных, которые обычно не используются в реальных проектах. Вместо этого вам, вероятно, придется иметь дело с полноразмерными изображениями, такими как те, что вы получаете от камер смартфонов. В этом блокноте мы рассмотрим, как загружать изображения и использовать их для обучения нейронных сетей.\n",
    "\n",
    "Мы будем использовать [набор данных с фотографиями кошек и собак](https://www.kaggle.com/c/dogs-vs-cats), доступный на Kaggle. Вот несколько примеров изображений:\n",
    "\n",
    "<img src='assets/dog_cat.png'>\n",
    "\n",
    "Мы используем этот набор данных для обучения нейронной сети, которая сможет различать кошек и собак. В наши дни это не кажется большим достижением, но некоторое время назад это было серьезной задачей для систем компьютерного зрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ загрузить изображения - это использовать `datasets.ImageFolder` из `torchvision` ([документация](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)). В общем случае, вы будете использовать `ImageFolder` следующим образом:\n",
    "\n",
    "```python\n",
    "dataset = datasets.ImageFolder('path/to/data', transform=transform)\n",
    "```\n",
    "\n",
    "где `'path/to/data'` - это путь к каталогу с данными, а `transform` - это последовательность операций обработки, созданная с помощью модуля [`transforms`](https://pytorch.org/vision/0.9/transforms.html) из `torchvision`. ImageFolder ожидает, что файлы и папки будут структурированы следующим образом:\n",
    "```\n",
    "root/dog/xxx.png\n",
    "root/dog/xxy.png\n",
    "root/dog/xxz.png\n",
    "\n",
    "root/cat/123.png\n",
    "root/cat/nsdf3.png\n",
    "root/cat/asd932_.png\n",
    "```\n",
    "\n",
    "где каждому классу соответствует своя папка (`cat` и `dog`) для изображений. Изображения затем маркируются классом, взятым из названия папки. Таким образом, изображение `123.png` будет загружаться с меткой класса `cat`. Вы можете скачать уже структурированный набор данных [отсюда](https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip). Набор разделен на обучающую и тестовую выборки.\n",
    "\n",
    "### Преобразования (transforms)\n",
    "\n",
    "Когда вы загружаете данные с помощью `ImageFolder`, вам нужно будет определить некоторые преобразования. Например, изображения имеют разные размеры, но нам нужно, чтобы все они были одного размера для обучения. Вы можете либо изменить их размер с помощью `transforms.Resize()`, либо обрезать с помощью `transforms.CenterCrop()`, `transforms.RandomResizedCrop()` и т. д. Также нам нужно будет преобразовать изображения в тензоры PyTorch с помощью `transforms.ToTensor()`. Обычно необходимо комбинировать эти преобразования в конвейер с использованием `transforms.Compose()`, который принимает список преобразований и выполняет их последовательно. Это выглядит примерно так (изменяем размер, затем обрезаем, а затем преобразовываем в тензор):\n",
    "\n",
    "```python\n",
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "```\n",
    "\n",
    "Существуют множество доступных преобразований, вы можете ознакомиться с [документацией](https://pytorch.org/vision/0.9/transforms.html). \n",
    "\n",
    "### Загрузчики данных (data loaders)\n",
    "\n",
    "После создания объекта `ImageFolder` вы должны передать его в [`DataLoader`](http://pytorch.org/docs/main/data.html#torch.utils.data.DataLoader). `DataLoader` принимает набор данных (dataset) (такой, который вы получаете от `ImageFolder`) и возвращает батчи изображений и соответствующие метки. Вы можете установить различные параметры, такие как размер батча и происходит ли перемешивание данных после каждой эпохи.\n",
    "\n",
    "```python\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "```\n",
    "\n",
    "Здесь `dataloader` является генератором. Чтобы получить данные из него, вам нужно пройтись по нему в цикле или преобразовать его в итератор и вызвать `next()`.\n",
    "\n",
    "```python\n",
    "# Проходя по циклу, получаем батч на каждой итерации \n",
    "for images, labels in dataloader:\n",
    "    pass\n",
    "\n",
    "# Получим один батч\n",
    "images, labels = next(iter(dataloader))\n",
    "```\n",
    " \n",
    ">**Упражнение:** Загрузите изображения из папки `Cat_Dog_data/train`, определите несколько преобразований (transform), затем создайте загрузчик данных (dataloader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "data_dir = 'Cat_Dog_data/train'\n",
    "\n",
    "transform = # TODO: создайте преобразования\n",
    "dataset = # TODO: создайте dataset с помощью ImageFolder\n",
    "dataloader = # TODO: используйте ImageFolder датасет, чтобы создать DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запустите код, чтобы протестировать загрузчик данных\n",
    "images, labels = next(iter(dataloader))\n",
    "helper.imshow(images[0], normalize=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы правильно загрузили данные, вы должны увидеть что-то похожее на это (ваше изображение будет другим):\n",
    "\n",
    "<img src='assets/cat_cropped.png' width=244>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аугментация данных (Data augmentation)\n",
    "\n",
    "Общая стратегия для обучения нейронных сетей - это введение случайности в сами входные данные. Например, вы можете случайным образом вращать, зеркалить, масштабировать и/или обрезать ваши изображения во время обучения. Это поможет вашей сети обобщать, поскольку она видит одни и те же изображения, но в разных местах, с разными размерами и в разных ориентациях и т. д.\n",
    "\n",
    "Чтобы случайным образом вращать, масштабировать, обрезать, а затем переворачивать ваши изображения, вы должны определить свои преобразования следующим образом:\n",
    "\n",
    "```python\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5], \n",
    "                                                            [0.5, 0.5, 0.5])])\n",
    "```\n",
    "\n",
    "Вы также, как правило, хотите нормализовать изображения с помощью `transforms.Normalize`. Вы передаете список средних значений и стандартных отклонений, а затем цветовые каналы нормализуются следующим образом\n",
    "\n",
    "```input[channel] = (input[channel] - mean[channel]) / std[channel]```\n",
    "\n",
    "Вычитание `mean` центрирует данные около нуля, а деление на `std` приводит значения к диапазону от -1 до 1. Нормализация помогает поддерживать веса сети ближе к нулю, что, в свою очередь, делает обратное распространение более стабильным. Без нормализации обучение сети может не быть успешным.\n",
    "\n",
    "Вы можете найти список всех [доступных преобразований здесь](http://pytorch.org/docs/0.3.0/torchvision/transforms.html). Когда вы тестируете, вы обычно хотите использовать изображения без применения преобразований, за исключением нормализации. Таким образом, для валидационных/тестовых изображений обычно просто изменяется размер и проводится обрезание.\n",
    "\n",
    ">**Упражнение:** Определите преобразования для обучающих и тестовых данных. Пока что не используйте нормализацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# TODO: Определите преобразования для обучающих и тестовых данных\n",
    "train_transforms = \n",
    "\n",
    "test_transforms = \n",
    "\n",
    "\n",
    "# Передайте преобразования сюда, затем выполните следующую ячейку, чтобы увидеть, как выглядят преобразования\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# измените переменную на trainloader или testloader \n",
    "data_iter = iter(trainloader)\n",
    "\n",
    "images, labels = next(data_iter)\n",
    "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
    "for ii in range(4):\n",
    "    ax = axes[ii]\n",
    "    helper.imshow(images[ii], ax=ax, normalize=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваши преобразованные изображения должны выглядеть примерно так.\n",
    "\n",
    "<center>Обучающие примеры:</center>\n",
    "<img src='assets/train_examples.png' width=500px>\n",
    "\n",
    "<center>Тестовые примеры:</center>\n",
    "<img src='assets/test_examples.png' width=500px>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
